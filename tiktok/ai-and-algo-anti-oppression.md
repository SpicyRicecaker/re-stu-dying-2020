# Main post
- Only answer one of the questions below free

## What is the knowledge exchanged between comp scientists and community participants? Why do you think this exchange of knowledge is done?

Looking at the info on the project page, it is said that participants will explore conceptually how to design an algorithm, for the ultimate purpose of designing a chatbot. This information is presumably coming from the experienced computer and data scientists that have knowledge of how a computer algorithm could be built. Then the participants, who come from professions such as art, of all ages and of all people, contribute their "cultural, street, and empirical knowledge". 

As for why this exchange occurs, the reasoning on the project's page is that it helps participants understand how their AI might be applied, and is even the foundation for the resulting chatbot. This is all for the purpose of creating a bot that is less biased, or taking a look at how existing systems can be made to be less biased. I think that this exchange of information helps both the scientists working on the project to understand what people are like in the community, as well as for the people to get a better close at hand understanding of the impact that it might have on their lives.

- Who?
  - The range of community participants in the project are very wide. All proartists, youth, elders, colored people
  - Data and computer scientists
- What?
  - Particpants explore conceptually how to design an algorithm
  - The particpants also talk about their cultural, street, and empirical knowledge, in an effort to interrupt these biased systems
- Why?
  - Helps people understand the application of AI, and it is the basis for algorithms developed


## What is this project's influence on who should be involved in the production of technological knowledge?

## What should we change producing and applying knowledge to make sure that AI is just and socially equitable?

# Two Comments

## Sunil res
- Include all groups, of all ethnicities and genders
- Include fair and equitable data
  - yes, but how do we define equitable
- Skew data for bias
  - how do we decide if the data is biased? Wouldn't the data be biased towards equitable data as you suggested?
  
Hey Sunil,
I like that your outline of making AI more just and equitable is very concise. However, I have a few questions. You mentioned that data from all groups and aspects of society should be represented, which I totally agree with, but I'm not sure how data could be skewed to correct for biases. 
This is because, I think that it would be difficult for an AI to assess its own biases, so some other party would have to judge the bias. Would another AI be responsible for skewing the data? Or would there be human judges?  

## People that are affected by technology
Hey Max,
I totally agree with your take that all people that are affected by the technology should be involved, however, I believe that your statement is inherently biased. This is because programmers are paid for their time and commitment to the topic, while people that are affected by the technology may or may not be. For example, people working minimum wage jobs or jobs that require a lot of movement may not have time to learn about an algorithm or even contribute their ideas. Or maybe some people just wouldn't care. I'm using a computer right now, that's technology that's affecting me, but I don't know half the processes or factories that goes into making it. So, while it would be great to teach people about every step of something, I don't think that it's feasible. 